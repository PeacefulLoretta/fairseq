# @package _group_

hydra:
  run:
    dir: .

defaults:
  - _self_
  - task: null
  - model: null
  - criterion: cross_entropy
  - optimizer: null
  - lr_scheduler: fixed
  - bpe: null
  - tokenizer: null
  - scoring: null
  - generation: null
  - common_eval: null
  - eval_lm: null

common:
  no_progress_bar: False
  log_interval: 1
  log_format: 'json'
  log_file: null
  aim_repo: null
  aim_run_hash: null
  tensorboard_logdir: ''
  wandb_project: null
  azureml_logging: False
  seed: 1337
  cpu: False
  tpu: False
  bf16: False
  memory_efficient_bf16: False
  fp16: True
  memory_efficient_fp16: False
  fp16_no_flatten_grads: False
  fp16_init_scale: 128
  fp16_scale_window: null
  fp16_scale_tolerance: 0.0
  on_cpu_convert_precision: False
  min_loss_scale: 0.0001
  threshold_loss_scale: null
  amp: False
  amp_batch_retries: 2
  amp_init_scale: 128
  amp_scale_window: null
  user_dir: null
  empty_cache_freq: 0
  all_gather_list_size: 16384
  model_parallel_size: 1
  quantization_config_path: null
  profile: False
  reset_logging: False
  suppress_crashes: False
  use_plasma_view: False
  plasma_path: '/tmp/plasma'

common_eval:
  path: null
  post_process: null
  quiet: False
  model_overrides: '{}'
  results_path: null

distributed_training:
  distributed_world_size: 32
  distributed_num_procs: 1
  distributed_rank: 0
  distributed_backend: 'nccl'
  distributed_init_method: 'tcp://learnfair1408:55498'
  distributed_port: 55498
  device_id: 0
  distributed_no_spawn: True
  not_fsdp_flatten_parameters: False

dataset:
  num_workers: 6
  skip_invalid_size_inputs_valid_test: True
  max_tokens: 1400000
  batch_size: null
  required_batch_size_multiple: 8
  required_seq_len_multiple: 1
  dataset_impl: null
  data_buffer_size: 10
  train_subset: 'train'
  valid_subset: 'valid'
  combine_valid_subsets: null
  ignore_unused_valid_subsets: False
  validate_interval: 5
  validate_interval_updates: 10000
  validate_after_updates: 0
  fixed_validation_seed: null
  disable_validation: False
  max_tokens_valid: 1400000
  batch_size_valid: '${dataset.batch_size}'
  max_valid_steps: null
  curriculum: 0
  gen_subset: 'test'
  num_shards: 1
  shard_id: 0
  grouped_shuffling: False
  update_epoch_batch_itr: True
  update_ordered_indices_seed: False
